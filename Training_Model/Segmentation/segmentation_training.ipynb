{"cells":[{"cell_type":"markdown","id":"3r0npA7GsIa8","metadata":{"id":"3r0npA7GsIa8"},"source":["# Mount tới Google Drive"]},{"cell_type":"code","execution_count":1,"id":"SVufMTbMsF3Y","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20201,"status":"ok","timestamp":1699149851210,"user":{"displayName":"Phúc Nguyễn Đình","userId":"09552229499731500254"},"user_tz":-420},"id":"SVufMTbMsF3Y","outputId":"9f4a78b7-c850-43f4-f4fd-d896b9b89880"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n","/content/drive/MyDrive/Training_Model/Segmentation\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","%cd /content/drive/MyDrive/Training_Model/Segmentation"]},{"cell_type":"markdown","id":"8375c6d7","metadata":{"id":"8375c6d7"},"source":["# Import thư viện cần thiết"]},{"cell_type":"code","execution_count":2,"id":"744be81e","metadata":{"executionInfo":{"elapsed":6790,"status":"ok","timestamp":1699149857998,"user":{"displayName":"Phúc Nguyễn Đình","userId":"09552229499731500254"},"user_tz":-420},"id":"744be81e"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import torchvision.transforms as transforms\n","\n","import os\n","import cv2\n","import numpy as np\n","import albumentations as A\n","import matplotlib.pyplot as plt\n","import time\n","\n","\n","from tqdm import tqdm\n","from copy import deepcopy\n","from datetime import datetime\n","from torch.utils.data import DataLoader, Dataset\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"markdown","id":"17db7387","metadata":{"id":"17db7387"},"source":["# Configuration"]},{"cell_type":"code","execution_count":23,"id":"0ecc3cb9","metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1699150821376,"user":{"displayName":"Phúc Nguyễn Đình","userId":"09552229499731500254"},"user_tz":-420},"id":"0ecc3cb9"},"outputs":[],"source":["\n","TQDM_BAR_FORMAT = '{l_bar}{bar:10}{r_bar}'  # Cần thiết cho tqdm\n","\n","# DATASET\n","images_file = 'data/images' # Tập chứa ảnh training\n","segs_file = 'data/labels'  # Tập chứa label của ảnh training\n","test_file = 'data/test'   # Tập chứa ảnh test\n","save_dir = 'train_val'   # Path lưu kết quả của tập test\n","ckpt_file = \"best.pt\"\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","val_size = 0.1          # Tỷ lệ chia tập val\n","\n","# AUGMENTATION\n","augmentation = True   # True nếu muốn tăng cường dữ liệu\n","hflip = True\n","vflip = True\n","rotate = True\n","\n","# TRAINING\n","lr = 5e-2         # learning rate\n","num_epochs = 30  # Số lượng epoch training\n","batch_size = 16   # Batch size"]},{"cell_type":"markdown","id":"8164a5df","metadata":{"id":"8164a5df"},"source":["# Chuẩn bị dữ liệu (Data Loader)\n"]},{"cell_type":"code","execution_count":24,"id":"421be6dd","metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1699150821943,"user":{"displayName":"Phúc Nguyễn Đình","userId":"09552229499731500254"},"user_tz":-420},"id":"421be6dd"},"outputs":[],"source":["class CustomDataLoader(Dataset):\n","    def __init__(self, data,\n","                     images_file,\n","                     segs_file,\n","                     is_val,\n","                     augmentation=False,\n","                     hflip=False,\n","                     vflip=False,\n","                     rotate=False):\n","\n","        self.ims_file = data\n","        self.images_file = images_file\n","        self.segs_file = segs_file\n","\n","        self.Tensor = transforms.ToTensor()\n","\n","        if is_val:\n","            self.aug = [False, hflip, vflip, rotate]\n","        else:\n","            self.aug = [augmentation, hflip, vflip, rotate]\n","\n","        self.do_aug = [A.HorizontalFlip(p=1), A.VerticalFlip(p=1), A.Rotate(limit=15, p=1.0)]\n","\n","\n","\n","    def __len__(self):\n","        return (len(self.ims_file))\n","\n","    def img2seg(self, path):\n","        return path.replace(self.images_file, self.segs_file).replace('.jpg', '.png')\n","\n","\n","    def preprocess(self, img, seg):\n","        h0, w0 = img.shape[:2]\n","\n","        img = cv2.resize(img, (160, 80), interpolation = cv2.INTER_LINEAR)\n","        seg = cv2.resize(seg, (160, 80), interpolation = cv2.INTER_LINEAR)\n","\n","        img = img/255\n","        img = img.transpose((2, 0, 1))[::-1]  # HWC to CHW, BGR to RGB\n","        img = np.ascontiguousarray(img)  # contiguous\n","\n","        seg = seg/255\n","        seg = seg.transpose((2, 0, 1))[::-1]  # HWC to CHW, BGR to RGB\n","        seg = np.ascontiguousarray(seg)  # contiguous\n","\n","        return img, seg\n","\n","\n","    def __getitem__(self, index):\n","\n","        img = cv2.imread(self.ims_file[index])\n","        seg = cv2.imread(self.img2seg(self.ims_file[index]))\n","\n","\n","        if self.aug[0]:\n","            img_pre, seg_pre = self.preprocess(img, seg)\n","            img_out, seg_out = [torch.from_numpy(img_pre)], [seg_pre]\n","            for i, f in enumerate(self.do_aug):\n","                if self.aug[i+1]:\n","                    au = f(image=img, mask=seg)\n","                    img_aug, seg_aug = au['image'], au['mask']\n","\n","                    img_aug, seg_aug = self.preprocess(img_aug, seg_aug)\n","\n","                    img_out.append(torch.from_numpy(img_aug))\n","                    seg_out.append(torch.from_numpy(seg_aug))\n","\n","            return img_out, seg_out\n","\n","        else:\n","            img_pre, seg_pre = self.preprocess(img, seg)\n","            img_out, seg_out = [torch.from_numpy(img_pre)], [torch.from_numpy(seg_pre)]\n","\n","            return img_out, seg_out"]},{"cell_type":"code","execution_count":25,"id":"0dd52362","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1699150822377,"user":{"displayName":"Phúc Nguyễn Đình","userId":"09552229499731500254"},"user_tz":-420},"id":"0dd52362","outputId":"cae2ec46-e4d6-4c76-e5e2-f9fd226b893a","scrolled":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Loading data: 100%|██████████| 434/434 [00:00<00:00, 227228.55it/s]"]},{"name":"stdout","output_type":"stream","text":["Training size: 390\n","Val size: 44\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["def split_data(images_file, segs_file, val_size):\n","    pbar = tqdm(os.listdir(images_file), total=len(os.listdir(images_file)), desc='Loading data', bar_format=TQDM_BAR_FORMAT)\n","    f = []\n","    for name in pbar:\n","        f.append(os.path.join(images_file, name))\n","\n","    train, val = train_test_split(f, test_size=val_size, train_size=(1-val_size))\n","\n","    return train, val\n","\n","\n","train, val = split_data(images_file, segs_file, val_size)\n","\n","train_dataset = CustomDataLoader(train,\n","                                 images_file,\n","                                 segs_file,\n","                                 is_val=False,\n","                                 augmentation=augmentation,\n","                                 hflip=hflip,\n","                                 vflip=vflip,\n","                                 rotate=rotate)\n","\n","val_dataset = CustomDataLoader(val,\n","                               images_file,\n","                               segs_file,\n","                               is_val=True,\n","                               augmentation=augmentation,\n","                               hflip=hflip,\n","                               vflip=vflip,\n","                               rotate=rotate)\n","\n","print(f'Training size: {len(train_dataset)}')\n","print(f'Val size: {len(val_dataset)}')\n","\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, pin_memory=True, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=batch_size, pin_memory=True, shuffle=False)"]},{"cell_type":"markdown","id":"89aea99d","metadata":{"id":"89aea99d"},"source":["# Khởi tạo Model"]},{"cell_type":"code","execution_count":26,"id":"a0f81d14","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1699150822682,"user":{"displayName":"Phúc Nguyễn Đình","userId":"09552229499731500254"},"user_tz":-420},"id":"a0f81d14","outputId":"82fb1298-d489-4ec1-fc56-a470823a367e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Input size: torch.Size([1, 3, 80, 160])\n","Total params: 144433\n"]}],"source":["def double_conv(in_ch, out_ch):\n","    conv_op = nn.Sequential(\n","        nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1),\n","        nn.BatchNorm2d(out_ch),\n","        nn.ReLU(inplace=True),\n","        nn.Conv2d(out_ch, out_ch, kernel_size=3, padding=1),\n","        nn.BatchNorm2d(out_ch),\n","        nn.ReLU(inplace=True)\n","    )\n","    return conv_op\n","\n","class UNet(nn.Module):\n","    def __init__(self, in_ch=3, out_ch=1):\n","        super(UNet, self).__init__()\n","        self.conv1 = double_conv(in_ch, 8)\n","        self.conv2 = double_conv(8, 16)\n","        self.conv3 = double_conv(16, 32)\n","        self.conv4 = double_conv(32, 64)\n","\n","        self.conv5 = double_conv(96, 32)\n","        self.conv6 = double_conv(48, 16)\n","        self.conv7 = double_conv(24, 8)\n","        self.pooling = nn.MaxPool2d(kernel_size=2)\n","\n","        self.upsample1 = nn.ConvTranspose2d(in_channels=64, out_channels=64, kernel_size=2, stride=2)\n","        self.upsample2 = nn.ConvTranspose2d(in_channels=32, out_channels=32, kernel_size=2, stride=2)\n","        self.upsample3 = nn.ConvTranspose2d(in_channels=16, out_channels=16, kernel_size=2, stride=2)\n","\n","        self.conv0 = nn.Conv2d(in_channels=8, out_channels=out_ch, kernel_size=1)\n","\n","\n","    def forward(self, x):\n","        #Encoder\n","        down1 = self.conv1(x)\n","        pool1 = self.pooling(down1)\n","        down2 = self.conv2(pool1)\n","        pool2 = self.pooling(down2)\n","        down3 = self.conv3(pool2)\n","        pool3 = self.pooling(down3)\n","        down4 = self.conv4(pool3)\n","\n","        #Decoder\n","        upsample1 = self.upsample1(down4)\n","        cat1 = torch.cat([down3, upsample1], dim=1)\n","        up1 = self.conv5(cat1)\n","        upsample2 = self.upsample2(up1)\n","        cat2 = torch.cat([down2, upsample2], dim=1)\n","        up2 = self.conv6(cat2)\n","        upsample3 = self.upsample3(up2)\n","        cat3 = torch.cat([down1, upsample3], dim=1)\n","        up3 = self.conv7(cat3)\n","\n","        outputs = self.conv0(up3)\n","\n","        return outputs\n","\n","img = torch.rand(1, 3, 80, 160)\n","model = UNet()\n","total_params = sum(p.numel() for p in model.parameters())\n","\n","print(f'Input size: {img.size()}')\n","print(f'Total params: {total_params}')"]},{"cell_type":"markdown","id":"90fd3cf0","metadata":{"id":"90fd3cf0"},"source":["# Training"]},{"cell_type":"code","execution_count":27,"id":"5a3c6832","metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1699150823066,"user":{"displayName":"Phúc Nguyễn Đình","userId":"09552229499731500254"},"user_tz":-420},"id":"5a3c6832"},"outputs":[],"source":["def dice_loss(input: torch.Tensor, target: torch.Tensor, reduce_batch_first: bool = False, epsilon: float = 1e-6):\n","    # Average of Dice coefficient for all batches, or for a single mask\n","#     assert input.size() == target.size()\n","#     assert input.dim() == 3 or not reduce_batch_first\n","\n","#     sum_dim = (-1, -2) if input.dim() == 2 or not reduce_batch_first else (-1, -2, -3)\n","\n","#     print(input.size())\n","#     print(target.size())\n","    inter = 2 * (input * target)\n","    sets_sum = input + target\n","    sets_sum = torch.where(sets_sum == 0, inter, sets_sum)\n","\n","    dice = (inter + epsilon) / (sets_sum + epsilon)\n","    return 1.0 - dice.mean()\n","\n","\n","def poly_lr_scheduler(lr, max_epochs, optimizer, epoch, power=2):\n","    lr = round(lr * (1 - epoch / max_epochs) ** power, 8)\n","    if lr < 5e-4:\n","      lr = 5e-4\n","    for param_group in optimizer.param_groups:\n","        param_group['lr'] = lr\n","\n","    return lr\n","\n","\n","def evaluate(model, val_loader):\n","    model.eval()\n","    num_val_batches = len(val_loader)\n","    dice_score = 0\n","\n","    for i, (img_l, target_l) in enumerate(val_loader):\n","\n","        for img, target in zip(img_l, target_l):\n","            img = img.to(device).float()\n","            true_masks = target.to(device).float()\n","            true_masks = torch.mean(true_masks, dim=1, keepdim=True)\n","            mask_pred = model(img)\n","            mask_pred = (torch.sigmoid(mask_pred) > 0.5).float()\n","\n","\n","            dice_score += dice_loss(mask_pred, true_masks, reduce_batch_first=False)\n","\n","\n","    model.train()\n","\n","    return dice_score / max(num_val_batches, 1)"]},{"cell_type":"code","execution_count":null,"id":"8c359ccd","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":1286253,"status":"error","timestamp":1699152109794,"user":{"displayName":"Phúc Nguyễn Đình","userId":"09552229499731500254"},"user_tz":-420},"id":"8c359ccd","outputId":"761b2b73-801f-40d4-e2aa-545c8cca4c7d"},"outputs":[],"source":["criterion = nn.BCEWithLogitsLoss()\n","optimizer = optim.Adam(model.parameters(), lr, (0.9, 0.999), eps=1e-08, weight_decay=5e-4)\n","model = model.to(device)\n","\n","best = 10000\n","dice_score = 0\n","\n","for epoch in range(num_epochs):\n","\n","    poly_lr_scheduler(lr, num_epochs, optimizer, epoch)\n","    for param_group in optimizer.param_groups:\n","        lr = param_group['lr']\n","\n","    model.train()\n","\n","    print(('\\n' + '%11s' * 4) % ('Epoch', 'Loss', 'Score', 'Lr'))\n","    pbar = enumerate(train_loader)\n","    total_batch = len(train_loader)\n","    pbar = tqdm(pbar, total=total_batch, bar_format=TQDM_BAR_FORMAT)\n","\n","    for i, (img_l, target_l) in pbar:\n","        for img, target in zip(img_l, target_l):\n","            img = img.to(device).float()\n","            true_masks = target.to(device).float()\n","            true_masks = torch.mean(true_masks, dim=1, keepdim=True)\n","            mask_pred = model(img)\n","\n","            optimizer.zero_grad()\n","            loss = criterion(mask_pred, true_masks)\n","            loss += dice_loss(torch.sigmoid(mask_pred), true_masks, reduce_batch_first=True)\n","\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","            last = loss.item()\n","\n","            pbar.set_description(('%13s' * 1 + '%13.4g'*3) %\n","                                     (f'{epoch}/{num_epochs - 1}', last, dice_score, lr))\n","\n","            dice_score = evaluate(model, val_loader)\n","\n","            if last < best:\n","                best = last\n","\n","            ckpt = {\n","                    'epoch': epoch,\n","                    'state_dict': model.state_dict(),\n","                    'optimizer': optimizer.state_dict(),\n","                    'loss': best,\n","                    'dice_score': dice_score,\n","                    'date': datetime.now().isoformat()\n","            }\n","\n","            torch.save(ckpt, ckpt_file)\n"]},{"cell_type":"markdown","id":"3c3c9419","metadata":{"id":"3c3c9419"},"source":["# Đánh giá với dữ liệu test"]},{"cell_type":"code","execution_count":null,"id":"27f2b297","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5039,"status":"ok","timestamp":1699152143456,"user":{"displayName":"Phúc Nguyễn Đình","userId":"09552229499731500254"},"user_tz":-420},"id":"27f2b297","outputId":"96840383-85ad-453d-c5d7-e6aaf0100c7a"},"outputs":[],"source":["model = UNet()\n","checkpoint = torch.load(ckpt_file)\n","model.load_state_dict(checkpoint['state_dict'])\n","model.to(device)\n","model.eval()\n","\n","images = os.listdir(test_file)\n","\n","for name in images:\n","    img = cv2.imread(os.path.join(test_file, name))\n","    img = cv2.resize(img, (160, 80), interpolation = cv2.INTER_LINEAR)\n","\n","    img = img/255\n","    img = img.transpose((2, 0, 1))[::-1]  # HWC to CHW, BGR to RGB\n","    img = np.ascontiguousarray(img)  # contiguous\n","\n","    img = torch.from_numpy(img)\n","    img = img.to(device).unsqueeze(0).float()\n","\n","#     print(img.shape)\n","\n","    with torch.no_grad():\n","        mask_pred = model(img)\n","\n","    mask_pred = (torch.sigmoid(mask_pred) > 0.5).float()\n","    to_save = mask_pred.squeeze(0).squeeze(0)\n","    to_save = (to_save.cpu().numpy()*255).astype(np.uint8)\n","\n","    save = f'{save_dir}/{name}.jpg'\n","    cv2.imwrite(save, to_save)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"}},"nbformat":4,"nbformat_minor":5}
